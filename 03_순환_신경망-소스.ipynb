{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/the-lm-book/blob/main/news_RNN_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re-HLYr0U_eL"
      },
      "source": [
        "<div style=\"display: flex; justify-content: center;\">\n",
        "    <div style=\"background-color: #f4f6f7; padding: 15px; width: 80%;\">\n",
        "        <table style=\"width: 100%\">\n",
        "            <tbody><tr>\n",
        "                <td style=\"vertical-align: middle;\">\n",
        "                    <span style=\"font-size: 14px;\">\n",
        "                        A notebook for <a rel=\"noopener\" href=\"https://www.thelmbook.com\">The Hundred-Page Language Models Book</a> by Andriy Burkov<br><br>\n",
        "                        Code repository: <a rel=\"noopener\" href=\"https://github.com/aburkov/theLMbook\">https://github.com/aburkov/theLMbook</a>\n",
        "                    </span>\n",
        "                </td>\n",
        "                <td style=\"vertical-align: middle;\">\n",
        "                    <a href=\"https://www.thelmbook.com\" target=\"_blank\" rel=\"noopener\">\n",
        "                        <img src=\"https://thelmbook.com/img/book.png\" width=\"80px\" alt=\"The Hundred-Page Language Models Book\">\n",
        "                    </a>\n",
        "                </td>\n",
        "            </tr>\n",
        "        </tbody></table>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k_iGNa_JVHp"
      },
      "source": [
        "# RNN 기반 언어 모델\n",
        "\n",
        "## 유틸리티 함수와 클래스\n",
        "\n",
        "다음 셀에서 필요 라이브러리를 임포트하고 유틸리티 함수와 모델 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yy0zjL_2ouOU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/redinblue/anaconda3/envs/pybuild/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# 필수 라이브러리 임포트\n",
        "import os               # 파일 및 경로 작업을 위한 라이브러리 (check_file_exists, extract_dataset)\n",
        "import urllib.request   # URL에서 데이터셋 파일 다운로드를 위한 라이브러리\n",
        "import tarfile          # .tar.gz 데이터셋 압축 해제를 위한 라이브러리\n",
        "import torch            # 텐서 연산과 딥러닝을 위한 메인 파이토치 라이브러리\n",
        "import torch.nn as nn   # 신경망 모듈, 층 및 유틸리티\n",
        "from torch.utils.data import DataLoader, IterableDataset  # 효율적인 데이터 로딩 및 스트리밍을 위한 라이브러리\n",
        "import random           # 재현성을 위한 난수 시드 설정\n",
        "from tqdm import tqdm   # 훈련 및 평가 시 진행률 표시를 위한 라이브러리\n",
        "import math             # exp()를 사용한 혼잡도 계산을 위한 라이브러리\n",
        "import re               # 텍스트 전처리를 위한 라이브러리 (숫자를 자리 표시자로 대체)\n",
        "from transformers import AutoTokenizer # 사전 훈련된 토크나이저 로드를 위한 라이브러리\n",
        "\n",
        "# ----------------------------\n",
        "# 유틸리티 함수\n",
        "# ----------------------------\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    다양한 파이썬 라이브러리에서 재현성을 위해 난수 시드를 설정합니다.\n",
        "    이렇게 하면 여러 실행에 걸쳐 랜덤한 연산이 동일한 결과를 제공합니다.\n",
        "    Args:\n",
        "        seed (int): 난수 생성을 위한 시드 값\n",
        "    \"\"\"\n",
        "    # 파이썬 내장 random 모듈의 시드 설정\n",
        "    random.seed(seed)\n",
        "    # 파이토치의 CPU 난수 생성기 시드 설정\n",
        "    torch.manual_seed(seed)\n",
        "    # 파이토치의 GPU 난수 생성기 시드 설정\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # 가능한 경우 cuDNN이 결정론적 알고리즘을 사용하도록 요청\n",
        "    # 참고: 이는 성능에 영향을 미칠 수 있으며 모든 경우에서 결정론을 보장하지 않을 수 있습니다\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # 특정 입력 크기에 대해 최적의 알고리즘을 찾는 cuDNN의 자동 튜너를 비활성화\n",
        "    # 일관된 동작을 보장하지만 입력 크기를 최적화하지 않으므로 더 느릴 수 있습니다\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class IterableTextDataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    메모리 효율적인 방식으로 텍스트 데이터를 처리하기 위한 반복 가능한 데이터셋입니다.\n",
        "    모든 데이터를 메모리에 로드하는 대신 디스크에서 데이터를 스트리밍합니다.\n",
        "    스트리밍 지원을 위해 파이토치의 IterableDataset을 상속합니다.\n",
        "    Args:\n",
        "        file_path (str): 문장이 포함된 텍스트 파일의 경로\n",
        "        tokenizer: 텍스트를 토큰으로 변환하기 위한 토크나이저 객체\n",
        "        max_length (int): 처리할 최대 시퀀스 길이 (기본값: 30)\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, tokenizer, max_length=30):\n",
        "        # 데이터 읽기를 위한 파일 경로 저장\n",
        "        self.file_path = file_path\n",
        "        # 텍스트 처리를 위한 토크나이저 저장\n",
        "        self.tokenizer = tokenizer\n",
        "        # 긴 시퀀스를 자르기 위한 최대 시퀀스 길이 설정\n",
        "        self.max_length = max_length\n",
        "        self._count_sentences()\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        데이터셋에 대한 반복자를 생성합니다.\n",
        "        이 메서드는 데이터셋을 반복할 때 호출됩니다.\n",
        "        Yields:\n",
        "            tuple: 언어 모델링을 위한 (input_sequence, target_sequence) 쌍\n",
        "                  input_sequence는 마지막 토큰까지의 시퀀스\n",
        "                  target_sequence는 한 위치 오른쪽으로 이동한 시퀀스\n",
        "        \"\"\"\n",
        "        # UTF-8 인코딩으로 읽기 모드에서 파일 열기\n",
        "        with open(self.file_path, 'r', encoding=\"utf-8\") as f:\n",
        "            # 파일의 각 라인(문장) 처리\n",
        "            for line in f:\n",
        "                # 앞뒤 공백 제거\n",
        "                sentence = line.strip()\n",
        "                # 모든 숫자를 ### 자리 표시자로 대체\n",
        "                # 이는 어휘 크기를 줄이고 모델의 일반화에 도움이 됩니다\n",
        "                sentence = re.sub(r\"\\d+\", \"###\", sentence)\n",
        "                # 문장을 토큰 ID로 변환\n",
        "                encoded_sentence = self.tokenizer.encode(\n",
        "                    sentence,\n",
        "                    max_length=self.max_length,\n",
        "                    truncation=True\n",
        "                )\n",
        "                # 최소 2개의 토큰이 있는 시퀀스만 사용\n",
        "                # (최소 하나의 입력과 하나의 타깃 토큰이 필요)\n",
        "                if len(encoded_sentence) >= 2:\n",
        "                    # 입력은 마지막을 제외한 모든 토큰\n",
        "                    input_seq = encoded_sentence[:-1]\n",
        "                    # 타깃은 첫 번째를 제외한 모든 토큰\n",
        "                    target_seq = encoded_sentence[1:]\n",
        "                    # 파이토치 텐서로 변환하여 반환\n",
        "                    yield torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._num_sentences\n",
        "\n",
        "    def _count_sentences(self):\n",
        "        print(f\"{self.file_path}에서 문장 수 계산 중...\")\n",
        "        with open(self.file_path, 'r', encoding=\"utf-8\") as f:\n",
        "            self._num_sentences = sum(1 for _ in f)\n",
        "        print(f\"{self.file_path}에서 {self._num_sentences}개의 문장을 찾았습니다.\")\n",
        "\n",
        "# ----------------------------\n",
        "# 데이터 다운로드 및 준비\n",
        "# ----------------------------\n",
        "def create_collate_fn(tokenizer):\n",
        "    \"\"\"\n",
        "    다양한 길이의 시퀀스를 배치로 만들기 위한 collate 함수를 생성합니다.\n",
        "    이 함수는 더 짧은 시퀀스를 배치에서 가장 긴 시퀀스와 일치하도록 패딩합니다.\n",
        "    Args:\n",
        "        tokenizer: 패딩 토큰 정보를 포함하는 토크나이저 객체\n",
        "    Returns:\n",
        "        function: 배치에서 패딩을 처리하는 collate 함수\n",
        "    \"\"\"\n",
        "    def collate_fn(batch):\n",
        "        # 배치에서 입력과 타깃 분리\n",
        "        input_seqs, target_seqs = zip(*batch)\n",
        "        # 토크나이저에서 패딩 토큰 ID 가져오기\n",
        "        pad_index = tokenizer.pad_token_id\n",
        "        # 입력 시퀀스를 동일한 길이로 패딩\n",
        "        input_padded = nn.utils.rnn.pad_sequence(input_seqs, batch_first=True, padding_value=pad_index)\n",
        "        # 타깃 시퀀스를 동일한 길이로 패딩\n",
        "        target_padded = nn.utils.rnn.pad_sequence(target_seqs, batch_first=True, padding_value=pad_index)\n",
        "        return input_padded, target_padded\n",
        "    return collate_fn\n",
        "\n",
        "def check_file_exists(filename):\n",
        "    \"\"\"\n",
        "    현재 디렉토리에 파일이 있는지 확인합니다.\n",
        "    Args:\n",
        "        filename (str): 확인할 파일 이름\n",
        "    Returns:\n",
        "        bool: 파일이 있으면 True, 없으면 False\n",
        "    \"\"\"\n",
        "    return os.path.exists(filename)\n",
        "\n",
        "def download_file(url):\n",
        "    \"\"\"\n",
        "    로컬에 파일이 없는 경우 주어진 URL에서 파일을 다운로드합니다.\n",
        "    다운로드 차단을 방지하기 위해 사용자 지정 User-Agent를 사용합니다.\n",
        "    Args:\n",
        "        url (str): 다운로드할 파일의 URL\n",
        "    Returns:\n",
        "        str: 다운로드된 파일의 이름 (\"news.tar.gz\")\n",
        "    \"\"\"\n",
        "    # URL에 관계없이 항상 news.tar.gz를 파일 이름으로 사용\n",
        "    filename = \"news.tar.gz\"\n",
        "    if not check_file_exists(filename):\n",
        "        print(f\"{url}에서 데이터셋 다운로드 중...\")\n",
        "        req = urllib.request.Request(\n",
        "            url,\n",
        "            headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        )\n",
        "        with urllib.request.urlopen(req) as response:\n",
        "            with open(filename, \"wb\") as out_file:\n",
        "                out_file.write(response.read())\n",
        "        print(\"다운로드가 완료되었습니다.\")\n",
        "    else:\n",
        "        print(f\"{filename}은(는) 이미 다운로드되었습니다.\")\n",
        "    return filename\n",
        "\n",
        "def is_within_directory(directory, target):\n",
        "    \"\"\"\n",
        "    절대 경로를 비교하여 대상 경로가 지정된 디렉토리 내에 있는지 확인합니다.\n",
        "    Args:\n",
        "        directory (str): 기본 디렉토리 경로\n",
        "        target (str): 확인할 대상 경로\n",
        "    Returns:\n",
        "        bool: 대상의 절대 경로가 디렉토리의 절대 경로로 시작하면 True\n",
        "    \"\"\"\n",
        "    abs_directory = os.path.abspath(directory)\n",
        "    abs_target = os.path.abspath(target)\n",
        "    prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "    return prefix == abs_directory\n",
        "\n",
        "def extract_dataset(filename):\n",
        "    \"\"\"\n",
        "    다운로드한 아카이브에서 train.txt와 test.txt를 추출합니다.\n",
        "    아카이브 내용에 대한 디버그 정보를 포함합니다.\n",
        "    Args:\n",
        "        filename (str): 아카이브 파일의 이름\n",
        "    Returns:\n",
        "        tuple: 추출된 train과 test 파일의 경로\n",
        "    \"\"\"\n",
        "    data_dir = os.path.join(os.path.dirname(filename), \"news\")\n",
        "    train_path = os.path.join(data_dir, \"train.txt\")\n",
        "    test_path = os.path.join(data_dir, \"test.txt\")\n",
        "\n",
        "    if check_file_exists(train_path) and check_file_exists(test_path):\n",
        "        print(\"데이터 파일이 이미 추출되었습니다.\")\n",
        "        return train_path, test_path\n",
        "\n",
        "    print(\"\\n아카이브 내용 나열:\")\n",
        "    with tarfile.open(filename, \"r:gz\") as tar:\n",
        "        for member in tar.getmembers():\n",
        "            print(f\"아카이브 멤버: {member.name}\")\n",
        "        print(\"\\n파일 추출 중...\")\n",
        "        # 먼저 현재 디렉토리로 추출\n",
        "        tar.extractall('.')\n",
        "\n",
        "    if not (check_file_exists(train_path) and check_file_exists(test_path)):\n",
        "        raise FileNotFoundError(f\"아카이브에서 필요한 파일을 찾을 수 없습니다. 위의 경로를 확인하십시오.\")\n",
        "\n",
        "    print(\"추출이 완료되었습니다.\")\n",
        "    return train_path, test_path\n",
        "\n",
        "def create_datasets(train_file, test_file, tokenizer, max_length=30):\n",
        "    \"\"\"\n",
        "    훈련과 테스트를 위한 IterableTextDataset 객체를 생성합니다.\n",
        "    이 데이터셋은 모든 데이터를 메모리에 로드하는 대신 디스크에서 데이터를 스트리밍합니다.\n",
        "    Args:\n",
        "        train_file (str): 훈련 데이터 파일의 경로\n",
        "        test_file (str): 테스트 데이터 파일의 경로\n",
        "        tokenizer: 텍스트 처리를 위한 토크나이저 객체\n",
        "    Returns:\n",
        "        tuple: (train_dataset, test_dataset) - 훈련과 테스트를 위한 데이터셋 객체\n",
        "    \"\"\"\n",
        "    # 훈련 데이터셋 생성\n",
        "    train_dataset = IterableTextDataset(train_file, tokenizer, max_length)\n",
        "    # 테스트 데이터셋 생성\n",
        "    test_dataset = IterableTextDataset(test_file, tokenizer, max_length)\n",
        "    # 데이터셋 크기 출력\n",
        "    print(f\"훈련 문장 수: {len(train_dataset)}\")\n",
        "    print(f\"테스트 문장 수: {len(test_dataset)}\")\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def create_dataloaders(train_dataset, test_dataset, batch_size, collate_fn):\n",
        "    \"\"\"\n",
        "    효율적인 데이터 반복을 위한 DataLoader 객체를 생성합니다.\n",
        "    Args:\n",
        "        train_dataset: 훈련 데이터셋\n",
        "        test_dataset: 테스트 데이터셋\n",
        "        batch_size (int): 배치당 시퀀스 수\n",
        "        collate_fn: 패딩과 배치 생성을 처리하는 함수\n",
        "    Returns:\n",
        "        tuple: (train_dataloader, test_dataloader) - 적절한 패딩으로\n",
        "               데이터 배치를 반복하기 위한 DataLoader 객체\n",
        "    \"\"\"\n",
        "    # 훈련 데이터 로더 생성\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,    # 패딩을 처리하는 함수\n",
        "        num_workers=0             # 워커 프로세스 수 (0 = 단일 프로세스)\n",
        "    )\n",
        "    # 테스트 데이터 로더 생성\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0\n",
        "    )\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "def download_and_prepare_data(url, batch_size, tokenizer, max_length=30):\n",
        "    \"\"\"\n",
        "    전체 데이터 준비 파이프라인을 처리하는 메인 함수입니다.\n",
        "    데이터를 다운로드하고, 추출하고, 필요한 데이터셋 객체를 생성합니다.\n",
        "    Args:\n",
        "        url (str): 데이터셋 아카이브를 다운로드할 수 있는 URL\n",
        "        batch_size (int): 데이터 로딩을 위한 배치 크기\n",
        "        tokenizer: 텍스트 처리를 위한 토크나이저 객체\n",
        "        max_length (int): 토큰화를 위한 최대 시퀀스 길이 (기본값: 30)\n",
        "    Returns:\n",
        "        tuple: (train_dataloader, test_dataloader) - 사용 준비된 데이터 로더\n",
        "    \"\"\"\n",
        "    # 1단계: URL에서 데이터셋 아카이브 다운로드\n",
        "    filename = download_file(url)\n",
        "    # 2단계: 아카이브에서 훈련 및 테스트 파일 추출\n",
        "    train_file, test_file = extract_dataset(filename)\n",
        "    # 3단계: 데이터 스트리밍을 위한 데이터셋 객체 생성\n",
        "    train_dataset, test_dataset = create_datasets(train_file, test_file, tokenizer, max_length)\n",
        "    # 4단계: 배치 생성을 처리하는 함수 생성\n",
        "    collate_fn = create_collate_fn(tokenizer)\n",
        "    # 5단계: 데이터 로더 생성 및 반환\n",
        "    return create_dataloaders(train_dataset, test_dataset, batch_size, collate_fn)\n",
        "\n",
        "def compute_loss_and_perplexity(model, dataloader, tokenizer, criterion, device, max_sentences=1000):\n",
        "    \"\"\"\n",
        "    데이터에 대한 손실과 혼잡도를 계산하여 모델 성능을 평가합니다.\n",
        "    Args:\n",
        "        model (nn.Module): 평가할 언어 모델\n",
        "        dataloader (DataLoader): 배치 시퀀스를 포함하는 데이터 로더\n",
        "        tokenizer: 패딩과 같은 특수 토큰을 처리하기 위한 토크나이저\n",
        "        criterion: 손실 함수 (보통 CrossEntropyLoss)\n",
        "        device: 계산을 실행할 장치 (cuda/cpu)\n",
        "        max_sentences (int): 평가할 최대 문장 수 (기본값: 1000)\n",
        "                           더 빠른 검증을 위해 평가를 하위 집합으로 제한합니다\n",
        "    Returns:\n",
        "        tuple: (average_loss, perplexity)\n",
        "               - average_loss: 토큰당 평균 손실 (패딩 제외)\n",
        "               - perplexity: exp(average_loss), 낮을수록 좋음\n",
        "    \"\"\"\n",
        "    # 모델을 평가 모드로 설정 (드롭아웃 등 비활성화)\n",
        "    model.eval()\n",
        "    # 손실 계산을 위한 카운터 초기화\n",
        "    total_loss = 0.0          # 모든 배치에 대한 총 손실 누적 변수\n",
        "    total_tokens = 0          # 총 토큰 수 카운터 (패딩 제외)\n",
        "    sentences_processed = 0    # 처리된 문장 수 카운터\n",
        "\n",
        "    # 효율성을 위해 그래디언트 계산 비활성화\n",
        "    with torch.no_grad():\n",
        "        # 진행률 표시와 함께 데이터 반복\n",
        "        for input_seq, target_seq in tqdm(dataloader, desc=\"평가 중\", leave=False):\n",
        "            # 입력과 타깃 시퀀스를 지정된 장치로 이동\n",
        "            input_seq = input_seq.to(device)      # 크기: (batch_size, seq_len)\n",
        "            target_seq = target_seq.to(device)    # 크기: (batch_size, seq_len)\n",
        "\n",
        "            # 현재 배치 크기 가져오기 (마지막 배치는 더 작을 수 있음)\n",
        "            batch_size_current = input_seq.size(0)\n",
        "\n",
        "            # 모델을 통한 포워드 패스\n",
        "            logits = model(input_seq)             # 크기: (batch_size, seq_len, vocab_size)\n",
        "\n",
        "            # 손실 계산을 위해 로짓과 타깃 재구성\n",
        "            logits = logits.reshape(-1, logits.size(-1))  # 크기: (batch_size * seq_len, vocab_size)\n",
        "            target = target_seq.reshape(-1)              # 크기: (batch_size * seq_len)\n",
        "\n",
        "            # 패딩 토큰을 제외하는 마스크 생성\n",
        "            mask = target != tokenizer.pad_token_id\n",
        "\n",
        "            # 패딩되지 않은 토큰에 대해서만 손실 계산\n",
        "            loss = criterion(logits[mask], target[mask])\n",
        "\n",
        "            # 카운터 업데이트\n",
        "            loss_value = loss.item() * mask.sum().item()  # 이 배치의 총 손실\n",
        "            total_loss += loss_value                      # 배치 손실 누적\n",
        "            total_tokens += mask.sum().item()             # 패딩이 아닌 토큰 수 계산\n",
        "\n",
        "            # 문장 카운터 업데이트 및 최대값에 도달했는지 확인\n",
        "            sentences_processed += batch_size_current\n",
        "            if sentences_processed >= max_sentences:\n",
        "                break\n",
        "\n",
        "    # 최종 메트릭 계산\n",
        "    average_loss = total_loss / total_tokens           # 토큰 수로 손실 정규화\n",
        "    perplexity = math.exp(average_loss)               # 손실을 혼잡도로 변환\n",
        "    return average_loss, perplexity\n",
        "\n",
        "def perform_model_evaluation(model, test_dataloader, criterion, tokenizer, device, contexts):\n",
        "    \"\"\"\n",
        "    손실 계산, 혼잡도 및 텍스트 생성을 포함한 모델 평가를 수행합니다.\n",
        "    Args:\n",
        "        model: 신경망 모델\n",
        "        test_dataloader: 테스트/검증 데이터를 포함하는 DataLoader\n",
        "        criterion: 손실 함수\n",
        "        tokenizer: 텍스트 생성을 위한 토크나이저\n",
        "        device: 계산을 실행할 장치 (cuda/cpu)\n",
        "        contexts: 텍스트 생성을 위한 문맥 문자열 목록\n",
        "    Returns:\n",
        "        tuple: (average_loss, perplexity)\n",
        "    \"\"\"\n",
        "    # 평가 모드로 전환\n",
        "    model.eval()\n",
        "\n",
        "    # 메트릭 계산\n",
        "    average_loss, perplexity = compute_loss_and_perplexity(\n",
        "        model, test_dataloader, tokenizer, criterion, device, max_sentences=1000\n",
        "    )\n",
        "    print(f\"검증 평균 손실: {average_loss:.4f}, 혼잡도: {perplexity:.2f}\")\n",
        "\n",
        "    # 문맥을 사용한 텍스트 생성\n",
        "    print(\"generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\\n\")\n",
        "    for context in contexts:\n",
        "        generated_text = generate_text(\n",
        "            model=model,          # 로드된 언어 모델\n",
        "            start_string=context, # 시작 문맥\n",
        "            tokenizer=tokenizer,  # 텍스트 변환을 위한 토크나이저\n",
        "            device=device,        # CPU 또는 GPU 장치\n",
        "            max_length=50         # 생성된 시퀀스의 최대 길이\n",
        "        )\n",
        "        print(f\"\\n문맥: {context}\")\n",
        "        print(f\"\\n생성된 텍스트: {generated_text}\\n\")\n",
        "\n",
        "    return average_loss, perplexity\n",
        "\n",
        "def generate_text(model, start_string, tokenizer, device, max_length=50):\n",
        "    \"\"\"\n",
        "    탐욕적 디코딩을 사용하여 주어진 시작 문자열에서 텍스트를 이어갑니다.\n",
        "    이 메서드는 항상 가장 가능성 있는 다음 토큰을 선택합니다.\n",
        "    Args:\n",
        "        model (nn.Module): 훈련된 언어 모델\n",
        "        start_string (str): 초기 텍스트\n",
        "        tokenizer: 텍스트 처리를 위한 토크나이저\n",
        "        device: 생성을 실행할 장치 (cuda/cpu)\n",
        "        max_length (int): 생성된 시퀀스의 최대 길이\n",
        "    Returns:\n",
        "        str: 생성된 텍스트 연속\n",
        "    \"\"\"\n",
        "    # 모델을 평가 모드로 설정\n",
        "    model.eval()\n",
        "\n",
        "    # 시작 문자열을 토큰 ID로 변환하고 장치로 이동\n",
        "    # return_tensors=\"pt\"는 목록 대신 파이토치 텐서를 반환합니다\n",
        "    tokens = tokenizer.encode(start_string, return_tensors=\"pt\", max_length=max_length, truncation=True).to(device)\n",
        "\n",
        "    # 입력 토큰으로 생성된 시퀀스 초기화\n",
        "    generated = tokens\n",
        "\n",
        "    # 한 번에 하나의 새 토큰 생성\n",
        "    for _ in range(max_length):\n",
        "        # 모델의 예측 가져오기\n",
        "        output = model(generated)                    # 크기: (1, seq_len, vocab_size)\n",
        "        # 다음 토큰에 대한 로짓 가져오기 (마지막 위치)\n",
        "        next_token_logits = output[0, -1, :]        # 크기: (vocab_size)\n",
        "        # 가장 높은 확률을 가진 토큰 선택 (탐욕적 디코딩)\n",
        "        # 예상 크기와 일치하도록 두 번 확장 (1, 1)\n",
        "        next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0).unsqueeze(0)\n",
        "        # 생성된 시퀀스에 새 토큰 추가\n",
        "        generated = torch.cat((generated, next_token_id), dim=1)\n",
        "        # 시퀀스 끝 토큰이 생성되면 중지\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # 토큰 ID를 다시 텍스트로 변환\n",
        "    generated_text = tokenizer.decode(generated.squeeze().tolist())\n",
        "    return generated_text\n",
        "\n",
        "def save_model(model, tokenizer, file_prefix):\n",
        "    model_state = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"vocab_size\": model.vocab_size,\n",
        "        \"emb_dim\": model.emb_dim,\n",
        "        \"num_layers\": model.num_layers,\n",
        "        \"pad_index\": model.pad_index,\n",
        "        \"training\": model.training  # 훈련 상태 저장\n",
        "    }\n",
        "    torch.save(model_state, f\"{file_prefix}_model.pth\")\n",
        "    tokenizer.save_pretrained(f\"{file_prefix}_tokenizer\")\n",
        "\n",
        "def load_model(file_prefix):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # 먼저 올바른 장치에 상태 딕셔너리 로드\n",
        "    model_state = torch.load(f\"{file_prefix}_model.pth\", map_location=device, weights_only=True)\n",
        "    # 상태 딕셔너리를 로드하기 전에 모델 생성 및 장치 이동\n",
        "    model = RecurrentLanguageModel(\n",
        "        model_state[\"vocab_size\"],\n",
        "        model_state[\"emb_dim\"],\n",
        "        model_state[\"num_layers\"],\n",
        "        model_state[\"pad_index\"]\n",
        "    ).to(device)\n",
        "    # 모델이 올바른 장치에 있은 후 상태 사전 로드\n",
        "    model.load_state_dict(model_state[\"state_dict\"])\n",
        "    # 평가 모드로 설정\n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(f\"{file_prefix}_tokenizer\")\n",
        "    return model, tokenizer\n",
        "\n",
        "def get_hyperparameters():\n",
        "    \"\"\"\n",
        "    모델 훈련을 위한 기본 하이퍼파라미터를 반환합니다.\n",
        "    Returns:\n",
        "        tuple: (emb_dim, num_layers, batch_size, learning_rate, num_epochs)\n",
        "    \"\"\"\n",
        "    emb_dim = 128         # 임베딩 차원\n",
        "    num_layers = 2        # RNN 층 수\n",
        "    batch_size = 128      # 훈련 배치 크기\n",
        "    learning_rate = 0.001 # 최적화를 위한 학습률\n",
        "    num_epochs = 1        # 훈련 에포크 수\n",
        "    context_size = 30     # 최대 입력 시퀀스 길이\n",
        "    return emb_dim, num_layers, batch_size, learning_rate, num_epochs, context_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrxY7I8Bml9c"
      },
      "source": [
        "# 모델 클래스\n",
        "\n",
        "RNN 언어 모델 클래스와 초기화 메서드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A82GEwnWmorj"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 순환 언어 모델 클래스\n",
        "# ----------------------------\n",
        "def initialize_weights(model):\n",
        "    \"\"\"\n",
        "    다차원 파라미터에는 Xavier 균등 초기화를 사용하고, 편향 및 기타 1차원 파라미터에는\n",
        "    균등 초기화를 사용하여 모델 가중치를 초기화합니다.\n",
        "    Args:\n",
        "        model (nn.Module): 가중치를 초기화해야 하는 파이토치 모델\n",
        "    \"\"\"\n",
        "    # 모델에서 이름을 가진 파라미터를 모두 반복\n",
        "    for name, param in model.named_parameters():\n",
        "        # 파라미터가 1차원 이상인 경우 확인 (예: 가중치 행렬)\n",
        "        if param.dim() > 1:\n",
        "            # 가중치 행렬에 Xavier 균등 초기화 사용\n",
        "            # 이는 분산을 일정하게 유지하여 기울기 소실/폭주을 방지하는 데 도움이 됩니다\n",
        "            nn.init.xavier_uniform_(param)\n",
        "        else:\n",
        "            # 1차원 파라미터(편향 등)의 경우 간단한 균등 초기화 사용\n",
        "            nn.init.uniform_(param)\n",
        "\n",
        "class ElmanRNNUnit(nn.Module):\n",
        "    \"\"\"\n",
        "    단일 Elman RNN 유닛(간단한 순환 신경망 셀)의 구현입니다.\n",
        "    입력의 타임스텝 하나를 처리하는 RNN의 기본 구성 요소입니다.\n",
        "    Args:\n",
        "        emb_dim (int): 임베딩/은닉 상태 벡터의 차원\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim):\n",
        "        super(ElmanRNNUnit, self).__init__()\n",
        "        # 은닉-은닉 가중치 행렬: 이전 은닉 상태를 변환\n",
        "        # 크기: (emb_dim, emb_dim)\n",
        "        self.Uh = nn.Parameter(torch.rand(emb_dim, emb_dim))\n",
        "        # 입력-은닉 가중치 행렬: 현재 입력을 변환\n",
        "        # 크기: (emb_dim, emb_dim)\n",
        "        self.Wh = nn.Parameter(torch.rand(emb_dim, emb_dim))\n",
        "        # 변환 합에 더해지는 편향 항\n",
        "        # 크기: (emb_dim,)\n",
        "        self.b = nn.Parameter(torch.rand(emb_dim))\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        \"\"\"\n",
        "        RNN 유닛의 한 타임스텝을 계산합니다.\n",
        "        Args:\n",
        "            x (torch.Tensor): 크기가 (batch_size, emb_dim)인 현재 입력 텐서\n",
        "            h (torch.Tensor): 크기가 (batch_size, emb_dim)인 이전 은닉 상태\n",
        "        Returns:\n",
        "            torch.Tensor: 크기가 (batch_size, emb_dim)인 새 은닉 상태\n",
        "        구현된 공식: h_new = tanh(x @ Wh + h @ Uh + b)\n",
        "        여기서 @는 행렬 곱셈을 나타냅니다\n",
        "        \"\"\"\n",
        "        # 1. 현재 입력 변환: x @ Wh\n",
        "        input_transform = x @ self.Wh\n",
        "        # 2. 이전 은닉 상태 변환: h @ Uh\n",
        "        hidden_transform = h @ self.Uh\n",
        "        # 3. 두 변환과 편향을 더함\n",
        "        # 4. tanh 활성화 함수를 적용하여 새 은닉 상태 얻기\n",
        "        # tanh는 값을 (-1, 1) 범위로 압축하여 기울기 폭주를 방지하는 데 도움이 됩니다\n",
        "        return torch.tanh(input_transform + hidden_transform + self.b)\n",
        "\n",
        "class ElmanRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    전체 시퀀스를 처리하는 다층 Elman RNN 구현입니다.\n",
        "    더 복잡한 패턴을 학습할 수 있는 더 깊은 네트워크를 만들기 위해 여러 RNN 유닛을 쌓습니다.\n",
        "    Args:\n",
        "        emb_dim (int): 임베딩 및 은닉 상태의 차원\n",
        "        num_layers (int): 쌓인 RNN 층의 수\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "        # 각 층에 대한 RNN 유닛 리스트 생성\n",
        "        # ModuleList를 사용하여 파이토치가 모든 파라미터를 추적하도록 함\n",
        "        self.rnn_units = nn.ModuleList(\n",
        "            [ElmanRNNUnit(emb_dim) for _ in range(num_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        모든 RNN 층을 통해 입력 시퀀스를 처리합니다.\n",
        "        Args:\n",
        "            x (torch.Tensor): 크기가 (batch_size, seq_len, emb_dim)인 입력 텐서\n",
        "        Returns:\n",
        "            torch.Tensor: 크기가 (batch_size, seq_len, emb_dim)인 출력 텐서\n",
        "        \"\"\"\n",
        "        # 입력 텐서에서 차원 가져오기\n",
        "        batch_size, seq_len, emb_dim = x.size()\n",
        "        # 각 층의 은닉 상태를 0으로 초기화\n",
        "        # 각 은닉 상태는 (batch_size, emb_dim) 크기를 가짐\n",
        "        h_prev = [\n",
        "            torch.zeros(batch_size, emb_dim, device=x.device)\n",
        "            for _ in range(self.num_layers)\n",
        "        ]\n",
        "        # 각 타임스텝의 출력을 저장할 변수\n",
        "        outputs = []\n",
        "        # 각 타임스텝 처리\n",
        "        for t in range(seq_len):\n",
        "            # 현재 타임스텝의 입력 가져오기\n",
        "            input_t = x[:, t]\n",
        "            # 각 층을 통해 처리\n",
        "            for l, rnn_unit in enumerate(self.rnn_units):\n",
        "                # 이 층의 새 은닉 상태 계산\n",
        "                h_new = rnn_unit(input_t, h_prev[l])\n",
        "                # 이 층의 은닉 상태 업데이트\n",
        "                h_prev[l] = h_new\n",
        "                # 이 층의 출력이 다음 층의 입력이 됨\n",
        "                input_t = h_new\n",
        "            # 최종 층의 출력을 결과에 추가\n",
        "            outputs.append(input_t)\n",
        "        # 모든 타임스텝의 출력을 단일 텐서로 쌓기\n",
        "        # 크기: (batch_size, seq_len, emb_dim)\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "class RecurrentLanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "    임베딩 층, 다층 RNN 및 출력 프로젝션 층을 결합한 완전한 언어 모델 구현입니다.\n",
        "    모델 아키텍처는 다음과 같습니다:\n",
        "    1. 입력 토큰 -> 임베딩 층 -> 임베딩 벡터\n",
        "    2. 임베딩 벡터 -> RNN 층 -> 문맥 벡터\n",
        "    3. 문맥 벡터 -> 선형 층 -> 어휘 예측\n",
        "    Args:\n",
        "        vocab_size (int): 어휘의 크기 (고유 토큰 수)\n",
        "        emb_dim (int): 임베딩 및 은닉 상태의 차원\n",
        "        num_layers (int): RNN 층의 수\n",
        "        pad_index (int): 패딩 토큰에 사용되는 인덱스\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, num_layers, pad_index):\n",
        "        super().__init__()\n",
        "        # 모델 파라미터 저장\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.pad_index = pad_index\n",
        "\n",
        "        # 임베딩 층: 토큰 인덱스를 밀집 벡터로 변환\n",
        "        # pad_index 토큰은 0 벡터로 매핑됩니다\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, pad_index)\n",
        "\n",
        "        # 시퀀스 처리를 위한 RNN 층\n",
        "        self.rnn = ElmanRNN(\n",
        "            emb_dim=emb_dim,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # RNN 출력을 어휘 예측으로 변환하는 최종 선형 층\n",
        "        # 출력 크기는 각 가능한 토큰에 대한 로짓을 얻기 위해 vocab_size입니다\n",
        "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        전체 모델을 통해 입력 시퀀스를 처리합니다.\n",
        "        Args:\n",
        "            x (torch.Tensor): 토큰 인덱스의 입력 텐서\n",
        "                            크기: (batch_size, seq_len)\n",
        "        Returns:\n",
        "            torch.Tensor: 다음 토큰 예측을 위한 출력 로짓\n",
        "                         크기: (batch_size, seq_len, vocab_size)\n",
        "        처리 과정:\n",
        "        1. 토큰 인덱스를 임베딩으로 변환\n",
        "        2. 임베딩을 RNN 층을 통해 처리\n",
        "        3. RNN 출력을 어휘 크기로 프로젝션\n",
        "        \"\"\"\n",
        "        # 토큰 인덱스를 임베딩으로 변환\n",
        "        # 크기: (batch_size, seq_len) -> (batch_size, seq_len, emb_dim)\n",
        "        embeddings = self.embedding(x)\n",
        "\n",
        "        # RNN 층을 통해 처리\n",
        "        # 크기: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, emb_dim)\n",
        "        rnn_output = self.rnn(embeddings)\n",
        "\n",
        "        # 어휘 크기로 프로젝션하여 로짓 얻기\n",
        "        # 크기: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, vocab_size)\n",
        "        logits = self.fc(rnn_output)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcutQEMSJg77"
      },
      "source": [
        "## 언어 모델 훈련하기\n",
        "\n",
        "다음 셀에서 데이터를 로드하고, 모델을 훈련 및 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s61ovCwawq3f",
        "outputId": "0d8e9781-d897-4ee5-8e5c-b50bb0835b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.thelmbook.com/data/news에서 데이터셋 다운로드 중...\n",
            "다운로드가 완료되었습니다.\n",
            "\n",
            "아카이브 내용 나열:\n",
            "아카이브 멤버: news\n",
            "아카이브 멤버: news/train.txt\n",
            "아카이브 멤버: news/test.txt\n",
            "\n",
            "파일 추출 중...\n",
            "추출이 완료되었습니다.\n",
            "news/train.txt에서 문장 수 계산 중...\n",
            "news/train.txt에서 22034911개의 문장을 찾았습니다.\n",
            "news/test.txt에서 문장 수 계산 중...\n",
            "news/test.txt에서 449693개의 문장을 찾았습니다.\n",
            "훈련 문장 수: 22034911\n",
            "테스트 문장 수: 449693\n",
            "총 훈련 가능한 매개변수: 8292619\n",
            "\n",
            "에포크 1/1 시작, 모델 훈련 모드: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   1%|          | 1561/172148 [01:09<2:17:46, 20.64it/s, loss=5.7887]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 6.3468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 5.5882, 혼잡도: 267.25\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's mother , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , and the first time\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , and the first time of the ##\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , the ##-year-old , who was a new-up , and the first time of the ##\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   1%|          | 1566/172148 [01:11<8:59:51,  5.27it/s, loss=5.7407] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President said : ' I 've been able to be a lot of the world . '' . 's a few-year-old , who was a new-up . '' . 's a few-year-old , who was a new-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   2%|▏         | 3123/172148 [02:19<2:14:32, 20.94it/s, loss=5.4449]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 5.4206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 5.2248, 혼잡도: 185.83\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow , who was a ##-year-old daughter , who was a ##-year-old daughter , who was a ##-year-old daughter , who was a ##-year-old daughter , who was a ##-year-old daughter\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City , the ##-year-old was a `` good thing . '' . 's a lot of people . '' . 's a statement . 's a lot of the world 's . '' . 's a statement . 's a\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , said : ' I 'm not going to be a good thing . '' . 's a lot of the world 's . '' . 's a statement . 's a lot of the world 's . '' . 's a statement\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   2%|▏         | 3129/172148 [02:21<7:18:49,  6.42it/s, loss=5.2717]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's mother , who was also found in the first time . 's apartment in the #### . 's apartment . 's a statement . 's a lot of the world 's . '' . 's a statement . 's\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   3%|▎         | 4688/172148 [03:29<2:07:17, 21.93it/s, loss=5.1412]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 5.1667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 5.0452, 혼잡도: 155.28\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow is a free kick in the UK . 's a statement . 's a lot of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York Times , the United States 's office , which is not a bit of the . 's a statement . 's a lot of the most of the most of the most of the most of the most of the most of the most of the most\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , who was a second-half years ago . 's a statement . 's a lot of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   3%|▎         | 4688/172148 [03:28<2:07:17, 21.93it/s, loss=5.1026]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the <rare> , who was a free kick in the #### . 's a statement . 's a lot of the most of the most of the most of the most of the most of the most of the most of the most of the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   4%|▎         | 6250/172148 [04:35<2:07:59, 21.60it/s, loss=5.0071]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 5.0186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.9321, 혼잡도: 138.67\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow said : ' I 'm not going to be a very good thing . '' , said : ' I 'm not going to be a very good thing . '' . 's said . 's a lot of the . 's a lot of\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City , the ##-year-old man , who was arrested in the ####s , the ##-year-old man , who was arrested in the ####s , which was a `` to the moment , '' he said . 's a lot\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricanes of the world 's most important thing that the government 's death is a little bit of the . 's a lot of the . '' 's said . 's a lot of the . 's a lot of the . '' '\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   4%|▎         | 6256/172148 [04:36<7:00:55,  6.57it/s, loss=5.0617]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's Office of the National Assembly , which is the first time in the ####s . 's ##-year-old , who was arrested in the ####s . 's ##-year-old , who was arrested in the ####s .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   5%|▍         | 7812/172148 [05:43<2:05:45, 21.78it/s, loss=4.8729]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.9175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.8394, 혼잡도: 126.40\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most recent years , the ##-year-old was a `` very good '' . '' . ' I 'm not going to be a very good . '' . ' I 'm not going to be a very good . '' . '\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , who has been a ##-year-old girl , was arrested in #### . 's . ' I 'm not going to be a very good thing . '' . ' I 'm not going to be a very good . ''\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricanes , the company said the government 's decision to be the first time in the ####s . 's . ' I 'm not going to be a very good thing . '' . ' I 'm not going to be a very good .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   5%|▍         | 7818/172148 [05:45<6:56:12,  6.58it/s, loss=4.7790]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the U.S. military spokesman said : 'The government 's decision to be the first time in the ####s , which is not supported by the U.S. military 's largest-scale tourist and the country '\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   5%|▌         | 9375/172148 [06:53<2:09:40, 20.92it/s, loss=4.8289]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.8448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.7693, 혼잡도: 117.84\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow , the ##-year-old was a `` very important thing to be able to do that . 's a lot of the . '' . ' I 'm not going to be a very good . 's a lot of the . '' .\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the incident was `` very important '' . 's a lot of the . 's , and I 'm not going to be a very good . 's a lot of the . '' . ' I 'm not going to be\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane is a very important thing . '' . ' I 'm not going to be a very good . 's a lot of the . '' . ' I 'm not going to be a very good . 's a lot of the . '' .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   5%|▌         | 9381/172148 [06:55<7:15:39,  6.23it/s, loss=4.7928]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the UK 's largest-###-year-old was also a very good time . 's a lot of the . 's , and I 'm not going to be a very good . 's a lot of the . ''\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   6%|▋         | 10940/172148 [08:03<2:08:29, 20.91it/s, loss=4.7191]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.7854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.7185, 혼잡도: 112.00\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most popularity of the country 's most popularity , the most important thing , ' he said . ' I 'm not going to be a bit of a great player . '' . ' I 'm not going to be a bit\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , the ##-year-old , who was arrested in the last two years , and the ##-year-old was found guilty of a man who was killed in the area of the crash . 's a lot of the . '\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane is a great player in the world . '' . ' I 'm not sure that the . '' said the man was not a bit of a . 's of the family , and the family 's family , and it 's a great thing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   6%|▋         | 10943/172148 [08:04<9:02:41,  4.95it/s, loss=4.6806]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the U.S. government has been the first time . 's a lot of the best . 's . ' I 'm not going to be a bit of a great player . '' . ' I 'm not going to be a\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   7%|▋         | 12502/172148 [09:13<2:06:29, 21.04it/s, loss=4.8445]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.7347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.6806, 혼잡도: 107.83\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most likely to be used in the country , the U.S. government has been a `` very good '' . ' '' . ' '' . ' I 'm not sure , ' he said . ' '' . ' I 'm not\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York Times : The ##-year-old was a `` very good thing '' . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure . ' '' . '\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , which is the first time in the ####s . 's . ' I 'm not sure that I was a good time . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure . ' '' .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   7%|▋         | 12508/172148 [09:15<6:56:47,  6.38it/s, loss=4.7856]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's office is not a `` very good '' . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure . ' '' . ' I 'm not sure\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   8%|▊         | 14066/172148 [10:24<2:06:57, 20.75it/s, loss=4.6836]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.6965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.6523, 혼잡도: 104.83\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been charged with the death of the `` <rare> '' and the first time to be a `` very good '' . ' . ' I 'm not sure I 'm not going to be a good way to the hospital . ' '' .\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , who has been charged with the murder of the murder of the . 's . ' I 'm not sure I 'm not going to be a good way to the hospital . ' '' . ' I 'm not sure I '\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the first time , the ##-year-old son , who was born in #### , and the ##-year-old son , who was born in #### . 's . ' I 'm not sure I 'm not going to be\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   8%|▊         | 14069/172148 [10:26<8:57:03,  4.91it/s, loss=4.7853]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's office , the company has been in the UK . '' . ' I 'm not sure I 'm not going to be a good way to the hospital . ' '' . ' I 'm not sure I 'm not going to be\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   9%|▉         | 15629/172148 [11:29<1:48:40, 24.00it/s, loss=4.5802]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.6668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.6083, 혼잡도: 100.31\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most popularity of the world is not a good way to be a good way to be a good way to be . '' . ' I 'm not sure that I was in the world . '' . ' I 'm not sure that\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government is not the first time . ' '' the report said . ' '' the statement said . ' '' the statement said . ' I 'm not sure that I was in the world . '' . ' I 'm not sure\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane in the world , which is not known as the world 's most expensive . '' . ' I 'm not sure that I was in the world . '' . ' I 'm not sure that I was in the world . '' . ' I\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:   9%|▉         | 15632/172148 [11:31<7:01:16,  6.19it/s, loss=4.6230]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's family , who is not a good way to the world . '' . ' I 'm not sure that I was in the world . '' . ' I 'm not sure that I was in the world . '' . ' I 'm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  10%|▉         | 17190/172148 [12:36<1:56:36, 22.15it/s, loss=4.6184]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.6404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5922, 혼잡도: 98.71\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's largest city of <rare> , the most popular , and the most popularity of the world is a very good . ' '' The <rare> said . ' '' the report said . ' '' the report said . ' '' the report\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New Yorkers are also investigating the incident . 's . 's <rare> , and the first time he was in the defensive half . 's . 's . 's <rare> , and the first-handed-up of\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , which is the first time in the ####s . 's of the . 's <rare> , and the first time he was in the defensive half . 's . 's . 's <rare> , and the first-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  10%|▉         | 17196/172148 [12:38<6:30:09,  6.62it/s, loss=4.6296]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's decision to be the first time in the ####s . 's of the . 's <rare> , the first time , and the family had been . ' '' the report said . ' '' the report said . ' '' the report\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  11%|█         | 18754/172148 [13:44<1:55:50, 22.07it/s, loss=4.5612]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.6166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5676, 혼잡도: 96.31\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most recent , the ##-year-old was in the first time in the ####s . 's . 's . ' I 'm not going to be a good time . '' . ' I 'm . ' '' . '\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government was `` very disappointing '' . ' '' the court heard . ' I 'm not going to be . ' '' the court heard . ' I 'm not going to be . ' '' the court heard . ' I\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old was arrested in the attacking half . 's . ' '' The ##-year-old said : ' I 'm not going to be a good time . '' . ' I 'm . ' '' .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  11%|█         | 18760/172148 [13:45<6:26:45,  6.61it/s, loss=4.5972]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's office , the government said . ' '' the court heard . ' I 'm not going to be . ' '' the court heard . ' I 'm not going to be . ' '' the court heard . ' I 'm . '\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  12%|█▏        | 20318/172148 [14:52<1:58:17, 21.39it/s, loss=4.5087]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5475, 혼잡도: 94.40\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been charged with the attack . 's . ' '' The ##-year-old was a member of the . 's . 's . ' I 'm sure I 'm not going to be a good thing . '' . ' I\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York Times : The ##-year-old was a member of the former England team-mate in #### . 's . ' '' The ##-year-old was arrested in the attack . 's . 's . ' '' The ##-year\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old man was arrested in the attack . 's . 's . ' I 'm sure I 'm not going to be a good thing . '' . ' I 'm sure . ' '' he said . '\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  12%|█▏        | 20321/172148 [14:54<8:41:28,  4.85it/s, loss=4.5878]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's office is not the same way . '' . ' . ' I 'm not sure that I was going to be a bit of a lot of people . ' '' he said . ' '' he said . ' '' he said . ' ''\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  13%|█▎        | 21880/172148 [15:57<1:35:42, 26.17it/s, loss=4.5891]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5297, 혼잡도: 92.73\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most recent figures show that the ##-year-old man was arrested on suspicion of murdering the incident . ' '' The ##-year-old said . ' '' The ##-year-old daughter , who was a ##-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government was `` deeply concerned '' by the government 's `` <rare> '' . '' ' . ' '' The ##-year-old said . ' '' The ##-year-old said . ' '' . ' '' The\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old man was arrested on suspicion of murdering the incident . ' '' The ##-year-old daughter , who was a ##-year-old daughter , who was a ##-year-old daughter , who\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  13%|█▎        | 21886/172148 [15:59<4:33:58,  9.14it/s, loss=4.5633]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's report has been criticised by the government to be a `` <rare> '' . '' ' . ' '' The ##-year-old said . ' '' The ##-year-old said . ' '' . ' '' The ##-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  14%|█▎        | 23443/172148 [17:05<1:52:36, 22.01it/s, loss=4.5246]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5188, 혼잡도: 91.73\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's government has been in the country 's election . '' . ' '' The ##-year-old son was arrested on suspicion of murdering the attack . ' '' The ##-year-old son was killed in the attacking half\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council 's government has been in the case , including the government 's government to be the first time . '' . ' '' The ##-year-old son was arrested on suspicion of murdering the attack . ' '' The ##-\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old girl was arrested on suspicion of murdering the attack . ' '' The ##-year-old son was arrested on suspicion of murdering the attack . ' '' The ##-year-old son was killed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  14%|█▎        | 23449/172148 [17:06<6:12:36,  6.65it/s, loss=4.5890]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the ####s , the ##-year-old man was arrested in the attacking half . ' '' The ##-year-old girl was found in the area . ' '' The ##-year-old son was arrested on suspicion of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  15%|█▍        | 25006/172148 [18:12<1:51:07, 22.07it/s, loss=4.5264]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.5094, 혼잡도: 90.87\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been in the past three years . ' . '' ' I 'm not sure that I was going to be a bit of a good idea . '' . ' . '' ' I 'm not sure that I was going to be a bit of\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government has been in the case of the attack . ' . '' ' I 'm not going to be a good idea . '' . ' . '' ' I 'm not sure that I was going to be a bit of a\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane in the ##-year-old man was killed in the attacking half . ' . '' ' I 'm not going to be a good idea . '' . ' . '' ' I 'm not sure that I was going to be a bit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  15%|█▍        | 25012/172148 [18:14<6:11:32,  6.60it/s, loss=4.5017]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the ####s , the ##-year-old man , who was in the first half , but he was not a good job . ' . '' ' I 'm not sure that I was going to be a bit of a good idea .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  15%|█▌        | 26569/172148 [19:19<1:49:36, 22.13it/s, loss=4.6288]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4914, 혼잡도: 89.25\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been in the UK 's most recent years , and the government 's government has been a `` very important '' . '' '' . 's of the <rare> , which is the first time , and the ##-year-old was\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York Times reported that the government has been in the country 's ####-#### . 's of the ##-year-old girl , who was in the area , and he was a member of the . 's . 's of the <rare\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , which is a major step in the UK 's most recent years . '' . 's a <rare> , which is a very good thing . '' ' , ' he said . ' '' The ##-year-old was arrested in the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  15%|█▌        | 26575/172148 [19:21<6:05:04,  6.65it/s, loss=4.5726]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the ####-###-#-# win over the ##th century , which is the first time in the ####s . 's Day . ' '' The ##-year-old was arrested in the attack , and the ##-year\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  16%|█▋        | 28131/172148 [20:24<54:38, 43.93it/s, loss=4.4242]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4865, 혼잡도: 88.81\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been in the world , and the government has been in the country . '' 's website . ' . ' '' The ##-year-old was in the hospital , and the girl was killed . ' . ' '' The ##-year-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York Times reported that the police officer was sentenced to ## years . ' . ' '' The ##-year-old was in the hospital , and he was in the hospital . ' . ' '' The ##-year-old was in the hospital ,\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old man , who was in the hospital , said : ' I 'm not sure that I was in the right direction . ' . '' ' , and the first time he was in the hospital . ' . ' ''\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  16%|█▋        | 28131/172148 [20:26<54:38, 43.93it/s, loss=4.3860]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's Office of the National Transportation Safety Board said the government was `` very concerned '' by the government . '' 's website . ' . ' '' The ##-year-old was in the hospital , and the girl was killed . '\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  17%|█▋        | 29694/172148 [21:33<1:51:02, 21.38it/s, loss=4.3199]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.5052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4750, 혼잡도: 87.80\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been a major part of the country 's most recent study , which is the most important thing to be . '' . ' '' The ##-year-old was in the middle of the day . ' . ' '' The ##-year-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , said the ##-year-old was in the case of the incident . ' '' The ##-year-old was in the middle of the day . ' . ' '' The ##-year-old was a member of the hospital\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the first time , the ##-year-old was killed in the attack , but the couple had been killed . ' . ' '' The ##-year-old was a member of the hospital . ' '' The ##-year-old was\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  17%|█▋        | 29700/172148 [21:34<6:08:05,  6.45it/s, loss=4.5153]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's decision to be the first time , the company said . ' '' The ##-year-old was in the middle of the day . ' . ' '' The ##-year-old was a member of the hospital . ' '' The ##\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  18%|█▊        | 31258/172148 [22:41<1:48:47, 21.58it/s, loss=4.5906]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4659, 혼잡도: 87.00\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's ##-year-old son , who was in the first half , the ##-year-old son of the ##-year-old son , who was in the first half , the ##-year-old son of the ##-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council has been a `` <rare> '' . '' ' , ' she said . ' . ' '' The ##-year-old was arrested in #### , and the ##-year-old was in the first half of the season . '\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane of the ##-year-old was arrested in #### , and the ##-year-old was in the first half of the season . 's . ' '' The ##-year-old was a member of the box is saved in the centre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  18%|█▊        | 31264/172148 [22:43<6:08:21,  6.37it/s, loss=4.4435]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the ####s , the ##-year-old was in the first half of the season , but the ##-year-old son was a member of the .## . ' '' The ##-year-old was a member of the Royal\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  19%|█▉        | 32822/172148 [23:50<1:46:19, 21.84it/s, loss=4.3685]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4558, 혼잡도: 86.13\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most recent study , which is the most popular with the most popularity of the world . '' . 's . 's . 's . 's . 's . 's <rare> , the ##-year-old girl\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government has been in the UK 's most recent years . '' . 's a `` <rare> '' and the first time , and the .### was a . '' ' I 'm not sure that I was in\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane center is a major factor in the UK , and the U.S. Embassy , the U.S. Embassy , the U.S. Embassy , the U.S. Embassy , the U.S\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  19%|█▉        | 32822/172148 [23:50<1:46:19, 21.84it/s, loss=4.5024]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's Office of the National Transportation Safety Board said the government was not allowed to be a `` good thing '' . ' . ' '' The ##-year-old girl was shot dead in the hospital . ' '' The ##-year-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  20%|█▉        | 34384/172148 [24:57<1:46:04, 21.65it/s, loss=4.5119]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4449, 혼잡도: 85.19\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been charged with murder . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-old was found guilty of murder . ' ''\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , who has been charged with murder , said the judge was notified . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-old was found guilty of murder . ' '' The ##-\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old , who was born in #### , was arrested in the attacking half of the ##-year-old . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  20%|█▉        | 34390/172148 [24:59<5:59:34,  6.39it/s, loss=4.2868]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's ##-year-old has been charged with murder . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-old was found guilty of murder . ' '' The ##-year-old was\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  21%|██        | 35948/172148 [26:06<1:45:54, 21.43it/s, loss=4.4227]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4386, 혼잡도: 84.65\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's lawyers have been in the UK for the first time . ' '' the ##-year-old boy was found dead in the city of the city . '' ' . ' '' The ##-year-old boy was found dead in\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City 's first-rounder was the first time in the ####s , which is the first time in the ####s . '' ' I 'm not sure that I was a good player . ' '' . ' '' The ##-year-\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane center , which is the largest city of the city , said the government has been in the UK . '' ' , ' I 'm not sure that I 'm not going to be . ' '' . ' '' The ##-year-old boy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  21%|██        | 35951/172148 [26:08<7:47:14,  4.86it/s, loss=4.4533]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The Presidential : The ##-year-old was a ##-year-old boy , who was in the hospital , said : ' I 'm not going to be a good player . ' '' . ' '' The ##-year-old boy was\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  22%|██▏       | 37509/172148 [27:15<1:43:48, 21.62it/s, loss=4.3772]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4321, 혼잡도: 84.11\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's first-half-year-old daughter , who was born in #### , said the ##-year-old daughter was arrested in the attack . ' . ' '' The ##-year-old daughter , who was born in #### , said\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government has been a `` very good '' . '' '' . ' '' The ##-year-old daughter , who was born in #### , said the ##-year-old daughter was arrested in the attack . ' . ' ''\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old man , who was born in #### , said : ' I 'm not going to be a bit of a good time . ' '' . ' '' The ##-year-old daughter , who was in the hospital\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  22%|██▏       | 37515/172148 [27:17<5:49:49,  6.41it/s, loss=4.5148]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's decision to be the first time , the government said the government has been a `` very good '' . ' '' . ' '' The ##-year-old daughter , who was born in #### , said the ##-year-old daughter was\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  23%|██▎       | 39069/172148 [28:21<54:54, 40.39it/s, loss=4.4114]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4175, 혼잡도: 82.89\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been in the UK and the United States . '' 's . 's . ' '' The ##-year-old was arrested in #### , and the ##-year-old was arrested in #### . 's . ' '' The ##-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council said the government 's decision to be held in the ####s . '' 's . 's . ' '' The ##-year-old was arrested in #### , and the ##-year-old was arrested in #### . 's\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old , who was in the middle of the day , he was arrested on the scene . ' . ' '' The ##-year-old was arrested in #### , and the ##-year-old was arrested in ####\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  23%|██▎       | 39079/172148 [28:23<2:14:51, 16.44it/s, loss=4.5121]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the ####s , the U.S. military has been in the UK and the U.S. military , which is the largest city of the country 's largest city . '' 's . 's . ' '' The ##-year\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  24%|██▎       | 40635/172148 [29:30<1:41:15, 21.65it/s, loss=4.3791]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4182, 혼잡도: 82.95\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's most recent figures , the company said the government 's decision to be the first time the next day of the election . '' 's . ' '' The ##-year-old boy was arrested in the attack , and the family had been\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council , who is the first of the first-team debut for the first time , he was a good player . ' '' The ##-year-old was found in the area . ' '' The ##-year-old boy was arrested in\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane center , the company said the government 's government has been a `` very good thing '' . ' '' The ##-year-old boy was arrested in the attack . ' '' The ##-year-old boy was arrested on suspicion of murder\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  24%|██▎       | 40641/172148 [29:32<5:38:54,  6.47it/s, loss=4.2536]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's decision to be the first time the ##-year-old was not a `` good thing '' . ' '' The ##-year-old boy was arrested on suspicion of murdering the murder of the police . ' '' The ##-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  25%|██▍       | 42198/172148 [30:39<1:38:56, 21.89it/s, loss=4.3199]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4142, 혼잡도: 82.61\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been in the first time in #### , but the first time he was in the first time . ' '' he said . ' '' she said . ' '' she said . ' '' she said . ' '' she said . ' '' she said .\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council has been a `` very good '' . '' '' he said . ' '' she said . ' '' she said . ' '' she said . ' '' she said . ' '' she said . ' '' she said . ' '' she said .\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , the ##-year-old man , who was born in #### , was arrested in #### . ' '' The ##-year-old was arrested in #### , but the case was not the first time . ' '' The ##-year-old\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  25%|██▍       | 42204/172148 [30:41<5:41:52,  6.33it/s, loss=4.5456]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's Office of the National Institutes of Health said the government has been a `` very good '' . '' '' he said . ' '' she said . ' '' she said . ' '' she said . ' '' she said . ' '' she said\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  25%|██▌       | 43763/172148 [31:48<1:38:10, 21.79it/s, loss=4.5058]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4079, 혼잡도: 82.10\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been a major deal with the U.S. government . '' '' the statement said . ' '' The ##-year-old girl was found guilty of murdering the murder of the murder of the ##-year-old girl . ' ''\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City 's first-team appearance is a bit of a new deal . ' '' The ##-year-old was a ##-year-old girl in a car crash in the area . ' '' The ##-year-old girl was found\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane Sandy is a very different place . '' ' I 'm not going to be a bit of a good job . '' '' he said . ' '' The ##-year-old girl was found guilty of murdering the murder of the murder of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  25%|██▌       | 43763/172148 [31:47<1:38:10, 21.79it/s, loss=4.3968]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President of the U.S. government has been a `` significant '' of the country 's most recent-day campaign . ' '' The ##-year-old was a member of the Royal Navy . ' '' The ##-year-old girl was\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  26%|██▋       | 45324/172148 [32:55<1:37:26, 21.69it/s, loss=4.3758]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.4015, 혼잡도: 81.57\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow 's first-round win in the Premier League , ## , ## , ## , ## , ## , ## , ## , ## , ## , was sentenced to ## years . ' '' The ##-year-old was a member of the group\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council has been a `` <rare> '' . ' '' The ##-year-old was a member of the National Trust . ' . ' '' The ##-year-old was a member of the National Park Service . ' . ' ''\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane of the disease is a long-term . '' . 's a `` <rare> '' . ' '' The ##-year-old was a member of the National Trust . ' . ' '' The ##-year-old was a member of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  26%|██▋       | 45330/172148 [32:56<5:28:51,  6.43it/s, loss=4.4785]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's Questions have been released on Monday . ' '' The ##-year-old was killed in a murder of ## years . ' . ' '' The ##-year-old was a member of the group 's ##-year-old\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  27%|██▋       | 46887/172148 [34:03<1:36:28, 21.64it/s, loss=4.5352]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "200064 샘플 처리 후, 평균 손실: 4.4290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.3992, 혼잡도: 81.39\n",
            "generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\n",
            "\n",
            "\n",
            "문맥: Moscow\n",
            "\n",
            "생성된 텍스트: Moscow has been a major part of the country 's largest city . '' '' said the company 's decision to be a `` very important '' . '' '' . ' '' The ##-year-old was arrested in #### . ' '' The ##-\n",
            "\n",
            "문맥: New York\n",
            "\n",
            "생성된 텍스트: New York City Council has been a `` very important '' in the UK . '' '' the former presidential candidate , the former president of the ####s . 's . ' '' The ##-year-old was arrested in #### . ' '' The ##-\n",
            "\n",
            "문맥: A hurricane\n",
            "\n",
            "생성된 텍스트: A hurricane , which is the most popularity of the world , is now a major part of the country 's largest city . '' '' said the report . 's . ' '' The ##-year-old was arrested in #### . ' '' The ##\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  27%|██▋       | 46893/172148 [34:05<5:23:07,  6.46it/s, loss=4.4558]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "문맥: The President\n",
            "\n",
            "생성된 텍스트: The President 's government has been a `` very important '' . '' '' he said . ' . ' '' The ##-year-old was arrested in #### , but the ##-year-old was arrested in #### . ' '' The ##-year-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "에포크 1/1:  28%|██▊       | 48248/172148 [35:04<1:30:03, 22.93it/s, loss=4.3283]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 99\u001b[0m\n\u001b[1;32m     95\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# 포워드 패스: 이 배치에 대한 모델 예측 가져오기\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 출력 크기: (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# 손실 계산을 위해 출력 및 타깃 텐서 재구성\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# - 출력: CrossEntropyLoss를 위해 (batch_size * seq_len, vocab_size)로 재구성\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# - 타깃: CrossEntropyLoss 요구 사항과 일치하도록 (batch_size * seq_len)로 재구성\u001b[39;00m\n\u001b[1;32m    104\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(batch_size_current \u001b[38;5;241m*\u001b[39m seq_len, vocab_size)\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[2], line 170\u001b[0m, in \u001b[0;36mRecurrentLanguageModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# RNN 층을 통해 처리\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# 크기: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, emb_dim)\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m rnn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# 어휘 크기로 프로젝션하여 로짓 얻기\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# 크기: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(rnn_output)\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36mElmanRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# 각 층을 통해 처리\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, rnn_unit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_units):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# 이 층의 새 은닉 상태 계산\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     h_new \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_prev\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# 이 층의 은닉 상태 업데이트\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     h_prev[l] \u001b[38;5;241m=\u001b[39m h_new\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[2], line 59\u001b[0m, in \u001b[0;36mElmanRNNUnit.forward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     55\u001b[0m hidden_transform \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUh\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 3. 두 변환과 편향을 더함\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 4. tanh 활성화 함수를 적용하여 새 은닉 상태 얻기\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# tanh는 값을 (-1, 1) 범위로 압축하여 기울기 폭주를 방지하는 데 도움이 됩니다\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtanh(input_transform \u001b[38;5;241m+\u001b[39m hidden_transform \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m)\n",
            "File \u001b[0;32m~/anaconda3/envs/pybuild/lib/python3.10/site-packages/torch/nn/modules/module.py:1949\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1944\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[0;32m-> 1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1951\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# 순환 신경망 언어 모델을 위한 메인 훈련 루프\n",
        "# 이 스크립트는 데이터 로딩, 모델 훈련, 검증 및 텍스트 생성을 포함한\n",
        "# 전체 훈련 과정을 처리합니다.\n",
        "# ----------------------------\n",
        "# 재현 가능한 결과를 보장하기 위해 난수 시드 초기화\n",
        "set_seed(42)\n",
        "\n",
        "# CUDA 지원 GPU가 있는지 확인하고 그에 따라 장치를 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 설정에서 모델 아키텍처 및 훈련 하이퍼파라미터 추출\n",
        "# emb_dim: 토큰 임베딩 및 은닉 상태의 차원\n",
        "# num_layers: 모델의 순환 층 수\n",
        "# batch_size: 미니 배치 크기\n",
        "# learning_rate: 옵티마이저 업데이트를 위한 단계 크기\n",
        "# num_epochs: 훈련 데이터셋을 완전히 통과하는 횟수\n",
        "# context_size: 최대 입력 시퀀스 길이\n",
        "emb_dim, num_layers, batch_size, learning_rate, num_epochs, context_size = get_hyperparameters()\n",
        "\n",
        "# 마이크로소프트의 Phi-3.5-mini 모델을 사용하여 토크나이저 초기화\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
        "\n",
        "# 모델이 처리해야 할 어휘사전의 크기 가져오기\n",
        "vocab_size = len(tokenizer)\n",
        "\n",
        "# 뉴스 데이터셋 다운로드 및 훈련과 테스트를 위한 DataLoader 객체 생성\n",
        "# DataLoader는 배칭 및 셔플링을 처리합니다\n",
        "data_url = \"https://www.thelmbook.com/data/news\"\n",
        "train_dataloader, test_dataloader = download_and_prepare_data(data_url, batch_size, tokenizer, context_size)\n",
        "\n",
        "# 지정된 아키텍처 매개변수로 RNN 언어 모델 초기화\n",
        "# vocab_size: 출력 층 차원 결정\n",
        "# emb_dim: 단어 임베딩 및 은닉 상태의 크기\n",
        "# num_layers: RNN 층 개수\n",
        "# pad_token_id: 더 짧은 시퀀스에 대한 패딩에 사용되는 특수 토큰 ID\n",
        "model = RecurrentLanguageModel(vocab_size, emb_dim, num_layers, tokenizer.pad_token_id)\n",
        "\n",
        "# 사용 가능한 경우 모델을 GPU로 이동\n",
        "model.to(device)\n",
        "\n",
        "# 사용자 지정 초기화 방식을 사용하여 모델 가중치 초기화\n",
        "# 이는 심층 신경망의 안정적인 훈련에 중요합니다\n",
        "initialize_weights(model)\n",
        "\n",
        "# 모델의 총 훈련 가능한 매개변수 수 계산 및 출력\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"총 훈련 가능한 매개변수: {total_params}\\n\")\n",
        "\n",
        "# 훈련을 위한 손실 함수(교차 엔트로피) 초기화\n",
        "# ignore_index=pad_token_id는 패딩 토큰이 손실에 기여하지 않도록 보장합니다\n",
        "# 이는 모델이 패딩 토큰을 예측하는 것을 학습하는 것을 방지합니다\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# 지정된 학습률로 AdamW 옵티마이저 초기화\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 평가 간격 설정(검증을 수행할 예시 수)\n",
        "# 200,000 예시는 훈련 시간과 모니터링 빈도 사이의 좋은 균형을 제공합니다\n",
        "eval_interval = 200_000\n",
        "examples_processed = 0  # 다음 평가까지의 진행 상황을 추적하기 위한 카운터\n",
        "\n",
        "# 평가 중에 샘플 텍스트를 생성하기 위한 테스트 컨텍스트 정의\n",
        "contexts = [\n",
        "    \"Moscow\",\n",
        "    \"New York\",\n",
        "    \"A hurricane\",\n",
        "    \"The President\"\n",
        "]\n",
        "\n",
        "# 메인 훈련 루프 - 지정된 수의 에포크 반복\n",
        "for epoch in range(num_epochs):\n",
        "    # 모델을 훈련 모드로 설정\n",
        "    model.train()\n",
        "    print(f\"에포크 {epoch+1}/{num_epochs} 시작, 모델 훈련 모드: {model.training}\")\n",
        "\n",
        "    # 이 에포크를 위한 추적 변수 초기화\n",
        "    total_loss = 0.0      # 모든 배치에 대한 손실 누적\n",
        "    total_tokens = 0      # 처리된 실제 토큰 수 카운터 (패딩 제외)\n",
        "\n",
        "    # 훈련 진행 상황 모니터링을 위한 진행률 표시줄 생성\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"에포크 {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # 훈련 데이터의 배치 반복\n",
        "    for batch_idx, (input_seq, target_seq) in enumerate(progress_bar):\n",
        "        # 사용 가능한 경우 입력 및 타깃 시퀀스를 GPU로 이동\n",
        "        input_seq = input_seq.to(device)\n",
        "        target_seq = target_seq.to(device)\n",
        "\n",
        "        # 재구성 작업을 위한 현재 배치 차원 가져오기\n",
        "        batch_size_current, seq_len = input_seq.shape\n",
        "\n",
        "        # 이전 배치의 그레이디언트 지우기\n",
        "        # 이는 파이토치가 기본적으로 그레이디언트를 누적하기 때문에 필요합니다\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 포워드 패스: 이 배치에 대한 모델 예측 가져오기\n",
        "        # 출력 크기: (batch_size, seq_len, vocab_size)\n",
        "        output = model(input_seq)\n",
        "\n",
        "        # 손실 계산을 위해 출력 및 타깃 텐서 재구성\n",
        "        # - 출력: CrossEntropyLoss를 위해 (batch_size * seq_len, vocab_size)로 재구성\n",
        "        # - 타깃: CrossEntropyLoss 요구 사항과 일치하도록 (batch_size * seq_len)로 재구성\n",
        "        output = output.reshape(batch_size_current * seq_len, vocab_size)\n",
        "        target = target_seq.reshape(batch_size_current * seq_len)\n",
        "\n",
        "        # 타깃에서 패딩이 아닌 토큰 수 계산\n",
        "        # 이는 여러 배치에 대한 평균 손실을 계산하기 위해 총 손실을 이 배치들의 토큰 수로 나누어야 하지만,\n",
        "        # criterion(output, target)은 배치당 토큰당 평균 손실을 반환하기 때문에 필요합니다.\n",
        "        # 따라서 배치당 손실을 얻기 위해 토큰당 손실에 토큰 수를 곱할 것입니다\n",
        "        non_padding_token_count = (target != tokenizer.pad_token_id).sum().item()\n",
        "\n",
        "        # 모델 예측과 실제 타깃 간의 손실 계산\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # 백워드 패스: 모델 매개변수에 대한 손실의 그레이디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 계산된 그레이디언트를 사용하여 모델 매개변수 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 이 배치에 대한 실제 손실 값 계산\n",
        "        # 배치의 총 손실을 얻기 위해 패딩이 아닌 토큰 수에 토큰당 손실을 곱합니다\n",
        "        loss_value = loss.item() * non_padding_token_count\n",
        "\n",
        "        # 에포크 통계를 위한 총 손실 누적\n",
        "        total_loss += loss_value\n",
        "\n",
        "        # 처리된 실제 토큰 총수 누적\n",
        "        total_tokens += non_padding_token_count\n",
        "\n",
        "        # 처리된 샘플 수 카운터 증가\n",
        "        examples_processed += batch_size_current\n",
        "\n",
        "        # 현재 배치 손실로 진행률 표시줄 업데이트\n",
        "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        # 지정된 수의 샘플을 처리한 후 주기적 평가\n",
        "        if examples_processed >= eval_interval:\n",
        "            # 마지막 eval_interval 예시에 대한 평균 손실 계산\n",
        "            avg_loss = total_loss / total_tokens\n",
        "            print(f\"\\n{examples_processed} 샘플 처리 후, 평균 손실: {avg_loss:.4f}\")\n",
        "\n",
        "            # 평가 모드로 전환\n",
        "            model.eval()\n",
        "\n",
        "            # 검증 메트릭 계산\n",
        "            # average_loss: 검증 세트의 평균 손실\n",
        "            # perplexity: 평균 손실의 지수, 낮을수록 좋음\n",
        "            # sentences_processed: 평가된 검증 시퀀스 수\n",
        "            average_loss, perplexity = compute_loss_and_perplexity(\n",
        "                model, test_dataloader, tokenizer, criterion, device, max_sentences=1000\n",
        "            )\n",
        "            print(f\"검증 평균 손실: {average_loss:.4f}, 혼잡도: {perplexity:.2f}\")\n",
        "\n",
        "            # 모델 성능을 정성적으로 평가하기 위해 샘플 텍스트 생성\n",
        "            print(\"generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\\n\")\n",
        "            for context in contexts:\n",
        "                # 각 테스트 문맥의 뒤를 잇는 텍스트 생성\n",
        "                generated_text = generate_text(\n",
        "                    model=model,          # 로드된 언어 모델\n",
        "                    start_string=context, # 시작 문맥\n",
        "                    tokenizer=tokenizer,  # 텍스트 변환을 위한 토크나이저\n",
        "                    device=device,        # CPU 또는 GPU 장치\n",
        "                    max_length=50         # 생성된 시퀀스의 최대 길이\n",
        "                )\n",
        "                print(f\"\\n문맥: {context}\")\n",
        "                print(f\"\\n생성된 텍스트: {generated_text}\")\n",
        "\n",
        "            # 계속 훈련하기 위해 훈련 모드로 다시 전환\n",
        "            model.train()\n",
        "\n",
        "            # 다음 평가 간격을 위해 카운터 재설정\n",
        "            examples_processed = 0\n",
        "            total_loss = 0.0\n",
        "            total_tokens = 0\n",
        "\n",
        "    # 에포크 종료 보고\n",
        "    if total_tokens > 0:\n",
        "        # 에포크에 대한 평균 손실 계산 및 표시\n",
        "        avg_loss = total_loss / total_tokens\n",
        "        print(f\"\\n에포크 {epoch+1}/{num_epochs}, 평균 손실: {avg_loss:.4f}\")\n",
        "    else:\n",
        "        # 처리된 토큰이 없는 경우 처리\n",
        "        print(f\"\\n에포크 {epoch+1}/{num_epochs} 완료.\")\n",
        "\n",
        "    # 에포크 종료 검증 수행\n",
        "    model.eval()\n",
        "    average_loss, perplexity = compute_loss_and_perplexity(\n",
        "        model, test_dataloader, tokenizer, criterion, device, max_sentences=1000\n",
        "    )\n",
        "    print(f\"검증 평균 손실: {average_loss:.4f}, 혼잡도: {perplexity:.2f}\\n\")\n",
        "\n",
        "    print(\"generate_text를 사용하여 문맥을 기반으로 텍스트 생성:\\n\")\n",
        "    for context in contexts:\n",
        "        # 각 테스트 문맥의 뒤를 잇는 텍스트 생성\n",
        "        generated_text = generate_text(\n",
        "            model=model,\n",
        "            start_string=context,\n",
        "            tokenizer=tokenizer,\n",
        "            device=device,\n",
        "            max_length=50  # 간결성을 위해 생성을 50 토큰으로 제한\n",
        "        )\n",
        "        print(f\"\\n문맥: {context}\")\n",
        "        print(f\"\\n생성된 텍스트: {generated_text}\")\n",
        "\n",
        "    # 다음 에포크를 위해 훈련 모드로 재설정\n",
        "    model.train()\n",
        "\n",
        "# 나중에 사용하기 위해 훈련된 모델과 토크나이저 저장\n",
        "# 여기에는 모델 아키텍처, 가중치 및 토크나이저 구성이 포함됩니다\n",
        "model_name = \"RNN_LM\"\n",
        "save_model(model, tokenizer, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoSevu4VJ-Rm"
      },
      "source": [
        "## 모델 테스트하기\n",
        "\n",
        "아래 셀에서 훈련된 모델을 로드하여 텍스트를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JmWY6HACeCd",
        "outputId": "f5d2308a-0e1f-4d8f-dc9c-8dcf576c4b4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검증 평균 손실: 4.2843, 퍼플렉시티: 72.55\n",
            "\n",
            "모델 테스트:\n",
            "\n",
            "\n",
            "프롬프트: Moscow\n",
            "\n",
            "생성된 응답: Moscow has been a major part of the country 's largest city of the country . '' 'We 're not going to be a good thing . '' ' I 'm not going to be a good player . '' ) . '' ' I 'm\n",
            "\n",
            "프롬프트: New York\n",
            "\n",
            "생성된 응답: New York 's first-time winner of the ##-year-old was a former team-mate in the second half . '' 'The .##-caliber rifle , a spokesman for the ##-year-old boy , who was\n",
            "\n",
            "프롬프트: A hurricane\n",
            "\n",
            "생성된 응답: A hurricane season is a huge amount of theft . '' 'The .##-caliber rifle , a spokesman for the Ministry of Justice . ' `` I 'm not going to be a good person . '' ' I 'm not going\n",
            "\n",
            "프롬프트: The President\n",
            "\n",
            "생성된 응답: The President 's office said the government had not been a `` significant '' . ' '' It 's not the case . ' '' It was a `` unacceptable '' . ' '' It 's not the case . ' '' It was a `` un\n"
          ]
        }
      ],
      "source": [
        "model_name = \"RNN_LM\"\n",
        "\n",
        "# 디스크에서 이전에 저장된 모델과 토크나이저 로드\n",
        "# 이는 훈련 후 정확한 모델 상태를 재생성합니다\n",
        "model, tokenizer = load_model(model_name)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "average_loss, perplexity = compute_loss_and_perplexity(\n",
        "    model, test_dataloader, tokenizer, criterion, device, max_sentences=1000\n",
        ")\n",
        "print(f\"검증 평균 손실: {average_loss:.4f}, 퍼플렉시티: {perplexity:.2f}\\n\")\n",
        "\n",
        "# 테스트 섹션의 헤더 출력\n",
        "print(\"모델 테스트:\\n\")\n",
        "\n",
        "# 모델 성능을 평가하기 위한 테스트 프롬프트 리스트\n",
        "contexts = [\n",
        "    \"Moscow\",\n",
        "    \"New York\",\n",
        "    \"A hurricane\",\n",
        "    \"The President\"\n",
        "]\n",
        "\n",
        "# 각 테스트 프롬프트를 반복하고 텍스트 생성\n",
        "for context in contexts:\n",
        "    # 탐욕적 디코딩(가장 가능성 있는 토큰)을 사용하여 텍스트 생성\n",
        "    generated_text = generate_text(\n",
        "        model=model,          # 로드된 언어 모델\n",
        "        start_string=context, # 시작 문맥\n",
        "        tokenizer=tokenizer,  # 텍스트 변환을 위한 토크나이저\n",
        "        device=device,        # CPU 또는 GPU 장치\n",
        "        max_length=50         # 생성된 시퀀스의 최대 길이\n",
        "    )\n",
        "\n",
        "    # 원본 프롬프트와 모델의 응답 출력\n",
        "    print(f\"\\n프롬프트: {context}\")\n",
        "    print(f\"\\n생성된 응답: {generated_text}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pybuild",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
